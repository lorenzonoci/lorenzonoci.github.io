---
permalink: /
title: "Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a fourth-year PhD student at ETH ZÃ¼rich, under the supervision of [Thomas Hofmann](https://da.inf.ethz.ch/). My research focuses on understanding large-scale modern neural networks, from initialization to training dynamics. I have been recently awarded a Google Fellowship. Prior to my PhD, I earned a Masterâ€™s degree in Data Science from ETH ZÃ¼rich and a Bachelorâ€™s degree from Politecnico di Milano. I also interned at Amazon in Luxembourg and spent two years living in Shanghai.


---


# News & Updates ðŸ“°

### [December 2024] Visiting Princeton.
I will visit [Boris Hanin](https://boris-hanin.github.io/) at Princeton ORFE during the next semester. I am very grateful for this opportunity! 


### [September 2024] Google PhD Fellowship.
I feel honored to have been awarded a [Google PhD Fellowship](https://research.google/programs-and-events/phd-fellowship/) that will generously support me for the next year. Thank you Google!


### [September 2024] Two papers accepted at Neurips 2024. 
Co-authors and I had two papers accepted at Neurips. In [Super Consistency of Neural Network Landscapes](https://arxiv.org/abs/2402.17457) we find out that the curvature of the landscape is independent of scale (i.e. the landscape "looks the same", no matter the scale). In [Understanding and Minimising Outlier Features in Neural Network Training](https://arxiv.org/abs/2405.19279) study the emergence of big outliers in LLM pre-training, and how modification of the architecture and optimizer can help!   

---

